# -*- coding: utf-8 -*-
"""Drug_toxicity_pred (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c03_mbJ7g0NY-TCimaOVF32d_khtVmhF
"""

# Ensure necessary libraries are installed
# pip install numpy scipy pandas tensorflow scikit-learn

import numpy as np
import pandas as pd
from scipy import io
from sklearn.metrics import roc_auc_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, BatchNormalization
from sklearn.model_selection import train_test_split

# Load the Tox21 dataset
y_tr = pd.read_csv('tox21_labels_train.csv.gz', index_col=0, compression="gzip")
y_te = pd.read_csv('tox21_labels_test.csv.gz', index_col=0, compression="gzip")
x_tr_dense = pd.read_csv('tox21_dense_train.csv.gz', index_col=0, compression="gzip").values
x_te_dense = pd.read_csv('tox21_dense_test.csv.gz', index_col=0, compression="gzip").values
x_tr_sparse = io.mmread('tox21_sparse_train.mtx.gz').tocsc()
x_te_sparse = io.mmread('tox21_sparse_test.mtx.gz').tocsc()

# Filter out very sparse features (5% threshold)
sparse_col_idx = ((x_tr_sparse > 0).mean(0) > 0.05).A.ravel()
x_tr = np.hstack([x_tr_dense, x_tr_sparse[:, sparse_col_idx].A])
x_te = np.hstack([x_te_dense, x_te_sparse[:, sparse_col_idx].A])

# Reshape data for 1D convolution (adding a channel dimension)
x_tr_cnn = np.expand_dims(x_tr, axis=-1)  # Shape: (samples, features, 1)
x_te_cnn = np.expand_dims(x_te, axis=-1)

# Define CNN + FCNN Hybrid Model
def build_cnn_fcnn(input_shape):
    model = Sequential([
        # 1D Convolutional Layer
        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),
        BatchNormalization(),
        Dropout(0.3),  # Prevent overfitting
        # Flatten before feeding into fully connected layers
        Flatten(),
        # Fully Connected Layers
        Dense(128, activation='relu'),
        Dropout(0.3),
        Dense(64, activation='relu'),
        Dropout(0.3),
        Dense(32, activation='relu'),
        Dense(1, activation='sigmoid')  # Output for binary classification
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['AUC'])
    return model

# List to store AUC scores
auc_scores = []

# Build and evaluate the CNN+FCNN model for each assay (toxicity task)
for target in y_tr.columns:
    # Filter rows where the target is not NaN
    rows_tr = np.isfinite(y_tr[target]).values
    rows_te = np.isfinite(y_te[target]).values

    # Build the CNN+FCNN model
    cnn_fcnn_model = build_cnn_fcnn((x_tr.shape[1], 1))  # Input shape for CNN

    # Train the model for 50 epochs
    cnn_fcnn_model.fit(x_tr_cnn[rows_tr], y_tr[target][rows_tr], epochs=100, batch_size=32, verbose=1)

    # Predict on test set
    p_te = cnn_fcnn_model.predict(x_te_cnn[rows_te])

    # Calculate ROC-AUC score
    auc_te = roc_auc_score(y_te[target][rows_te], p_te)

    # Print the AUC score for this toxicity task
    print("%15s: %3.5f" % (target, auc_te))

    # Append the score to the list
    auc_scores.append(auc_te)

# Calculate and print the average AUC score
average_auc = np.mean(auc_scores)

# Print individual AUC scores
print("\nIndividual ROC-AUC Scores:")
for target, score in zip(y_tr.columns, auc_scores):
    print("%15s: %3.5f" % (target, score))

# Print average ROC-AUC score
print("\nAverage ROC-AUC Score: %.5f" % average_auc)